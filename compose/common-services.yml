version: '2'

services:
  gatling: 
    image: lmagnin/docker-nats-connector-spark:gatling
    environment:
      - GATLING.TO_NATS.SUBJECT=INPUT
      
  nats:
    image: nats
    ports:
      - 4222:4222
      - 8222:8222
      - 6222:6222
      
  app: 
    image: lmagnin/docker-nats-connector-spark:app
#    image: logimethods/docker-nats-connector-spark-app
    command: "INPUT OUTPUT"
      
  monitor: 
    image: lmagnin/docker-nats-connector-spark:monitor
    command: "OUTPUT"

  spark-master:
    container_name: spark-master
    image: gettyimages/spark:1.5.2-hadoop-2.6
    command: spark-class org.apache.spark.deploy.master.Master -h spark-master
    hostname: spark-master
    environment:
      - "SERVICE_NAME=spark-master"
#      - "constraint:node==swarm-master"
      - "SPARK_CONF_DIR: /conf"
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./conf/master:/conf
      - ./data:/usr/local/spark/data

  spark-slave:
    image: gettyimages/spark:1.5.2-hadoop-2.6
    command: spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - "SPARK_CONF_DIR: /conf"
      - "SPARK_WORKER_CORES: 2"
      - "SPARK_WORKER_MEMORY: 2g"
      - "SPARK_WORKER_PORT: 8881"
      - "SPARK_WORKER_WEBUI_PORT: 8081"
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8081
#    ports:
#      - 8081:8081
    volumes:
      - ./conf/slave:/conf
      - ./data:/usr/local/spark/data

  spark-shell:
#    image: lmagnin/docker-nats-connector-spark:shell
    image: logimethods/docker-nats-connector-spark-shell
